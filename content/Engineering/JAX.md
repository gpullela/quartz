---
title: JAX
date: 2023-11-09
---
## Introduction

[[JAX]] was developed by Google internally as a [[Machine Learning|machine learning]] framework for transforming numerical functions.  [[JAX]] stands for [[JIT]] (just-in-time compilation), [[autograd]] (automatic gradient for native [[Python]] and Numpy functions), and [[XLA]] (Accelerated Linear Algebra, written by Google, for [TensorFlow](https://www.tensorflow.org/)).  

[[JAX]] is meant for use with [[Python]].  Thanks to features like [[JIT]] and [[XLA]], [[JAX]] code can be run on [[CPU|CPUs]], [[GPU|GPUs]], and [[TPU|TPUs]], running at mind boggling speed when using the latter two accelerators if your code follows relevant constraints.

---
## Video(s)



---
## Resources
1. [JAX - GitHub](https://github.com/google/jax)
2. [JAX - readthedocs.io](https://jax.readthedocs.io/en/latest/index.html)

